{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be6d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e2c24f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T11:50:57.151683Z",
     "start_time": "2023-06-06T11:50:54.829408Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "def calculate_confusion_matrix(y_true, y_pred, num_classes):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(num_classes))\n",
    "    return cm\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def inv_normalize(tensor):\n",
    "    return (np.transpose(tensor.numpy(), axes=[1, 2, 0]) * data_module.imnet_std) + data_module.imnet_mean\n",
    "\n",
    "def list_to_image_grid(images, titles, cols=3):\n",
    "    \"\"\"Display a list of images as a grid with titles.\"\"\"\n",
    "    rows = math.ceil(len(images) / cols)\n",
    "    if titles is None:\n",
    "        titles = ['']*len(images)\n",
    "    plt.figure(figsize=(16, 14))\n",
    "    for n, (image, title) in enumerate(zip(images, titles)):\n",
    "        plt.subplot(rows, cols, n + 1)\n",
    "        plt.imshow(inv_normalize(image))\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c318b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "torch.set_float32_matmul_precision('high')\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9138f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(pl.LightningModule):\n",
    "    def __init__(self, num_angle_classes=5, num_level_classes=6):\n",
    "        super().__init__()\n",
    "        self.resnet = torchvision.models.resnet18(pretrained=True)\n",
    "        self.resnet.fc = torch.nn.Linear(self.resnet.fc.in_features, 512)\n",
    "        self.angle_head = torch.nn.Linear(512, num_angle_classes)\n",
    "        self.level_head = torch.nn.Linear(512, num_level_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        angle_logits = self.angle_head(x)\n",
    "        level_logits = self.level_head(x)\n",
    "        return angle_logits, level_logits\n",
    "    \n",
    "    def forward_angle(self, x):\n",
    "        x = self.resnet(x)\n",
    "        angle_logits = self.angle_head(x)\n",
    "        return angle_logits\n",
    "\n",
    "    def forward_level(self, x):\n",
    "        x = self.resnet(x)\n",
    "        level_logits = self.level_head(x)\n",
    "        return level_logits\n",
    "    \n",
    "    def test_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        x, target = batch\n",
    "\n",
    "        if dataloader_idx == 0:\n",
    "            output = self.forward_angle(x)\n",
    "        else:\n",
    "            output = self.forward_level(x)\n",
    "        \n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "        loss = loss_func(output, target)\n",
    "\n",
    "        preds = torch.argmax(output, dim=1)\n",
    "        acc = torch.sum(preds == target).item() / len(target)\n",
    "        \n",
    "        if dataloader_idx == 0:            \n",
    "            self.log(\"test_loss_angle\", loss, prog_bar=True)\n",
    "            self.log(\"test_angle_acc\", acc, prog_bar=True)\n",
    "            \n",
    "            # Calculate confusion matrix\n",
    "            cm = calculate_confusion_matrix(target.cpu().numpy(), preds.cpu().numpy(), num_classes=5)\n",
    "            \n",
    "            tb = self.logger.experiment\n",
    "            df_cm = pd.DataFrame(\n",
    "                cm,\n",
    "                index=data_module.angle_data.class_to_idx.values(),\n",
    "                columns=data_module.angle_data.class_to_idx.values(),\n",
    "            )\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(10, 5))\n",
    "            fig.subplots_adjust(left=0.05, right=.65)\n",
    "            sn.set(font_scale=1.2)\n",
    "            sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, fmt='d', ax=ax)\n",
    "            ax.legend(\n",
    "                data_module.angle_data.class_to_idx.values(),\n",
    "                data_module.angle_data.class_to_idx.keys(),\n",
    "                handler_map={int: IntHandler()},\n",
    "                loc='upper left',\n",
    "                bbox_to_anchor=(1.2, 1)\n",
    "            )\n",
    "            buf = io.BytesIO()\n",
    "\n",
    "            plt.savefig(buf, format='jpeg', bbox_inches='tight')\n",
    "            buf.seek(0)\n",
    "            im = Image.open(buf)\n",
    "            im = torchvision.transforms.ToTensor()(im)\n",
    "            tb.add_image(\"test_confusion_matrix_angle\", im, global_step=self.current_epoch)\n",
    "        else:             \n",
    "            self.log(\"test_loss_level\", loss, prog_bar=True)\n",
    "            self.log(\"test_level_acc\", acc, prog_bar=True)\n",
    "            \n",
    "            # Calculate confusion matrix\n",
    "            cm = calculate_confusion_matrix(target.cpu().numpy(), preds.cpu().numpy(), num_classes=6)\n",
    "            \n",
    "            tb = self.logger.experiment\n",
    "            df_cm = pd.DataFrame(\n",
    "                cm,\n",
    "                index=data_module.level_data.class_to_idx.values(),\n",
    "                columns=data_module.level_data.class_to_idx.values(),\n",
    "            )\n",
    "\n",
    "            fig, ax = plt.subplots(figsize=(10, 5))\n",
    "            fig.subplots_adjust(left=0.05, right=.65)\n",
    "            sn.set(font_scale=1.2)\n",
    "            sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}, fmt='d', ax=ax)\n",
    "            ax.legend(\n",
    "                data_module.level_data.class_to_idx.values(),\n",
    "                data_module.level_data.class_to_idx.keys(),\n",
    "                handler_map={int: IntHandler()},\n",
    "                loc='upper left',\n",
    "                bbox_to_anchor=(1.2, 1)\n",
    "            )\n",
    "            buf = io.BytesIO()\n",
    "\n",
    "            plt.savefig(buf, format='jpeg', bbox_inches='tight')\n",
    "            buf.seek(0)\n",
    "            im = Image.open(buf)\n",
    "            im = torchvision.transforms.ToTensor()(im)\n",
    "            tb.add_image(\"test_confusion_matrix_level\", im, global_step=self.current_epoch)\n",
    "        \n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        x, target = batch\n",
    "        \n",
    "        output_angle = self.forward_angle(x)\n",
    "        output_level = self.forward_level(x)\n",
    "\n",
    "        preds_angle = torch.argmax(output_angle, dim=1)\n",
    "        preds_level = torch.argmax(output_level, dim=1)\n",
    "        \n",
    "        return {'img': x, 'angle': preds_angle, 'level': preds_level, 'target': target, 'dl': dataloader_idx}\n",
    "        \n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00423f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â load from a checkpoint\n",
    "model = ResNet(num_angle_classes=5, num_level_classes=6)\n",
    "model = model.load_from_checkpoint('model.ckpt') #95 94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8957666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir, batch_size, val_size=0.1, train_size=0.7):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.val_size = val_size\n",
    "        self.train_size = train_size\n",
    "        self.imnet_mean = [0.485, 0.456, 0.406]\n",
    "        self.imnet_std = [0.229, 0.224, 0.225]\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        angle_transforms = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=self.imnet_mean, std=self.imnet_std)\n",
    "        ])\n",
    "        self.angle_data = torchvision.datasets.ImageFolder(os.path.join(self.data_dir, 'angle'), transform=angle_transforms)\n",
    "        train_size = int(len(self.angle_data) * self.train_size)\n",
    "        val_size = int(len(self.angle_data) * self.val_size)\n",
    "        test_size = len(self.angle_data) - train_size - val_size\n",
    "        self.angle_data_train, self.angle_data_val, self.angle_data_test = random_split(self.angle_data, [train_size, val_size, test_size])\n",
    "\n",
    "        \n",
    "        level_transforms = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=self.imnet_mean, std=self.imnet_std)\n",
    "        ])\n",
    "        self.level_data = torchvision.datasets.ImageFolder(os.path.join(self.data_dir, 'level'), transform=level_transforms)\n",
    "        train_size = int(len(self.level_data) * self.train_size)\n",
    "        val_size = int(len(self.level_data) * self.val_size)\n",
    "        test_size = len(self.level_data) - train_size - val_size\n",
    "        self.level_data_train, self.level_data_val, self.level_data_test = random_split(self.level_data, [train_size, val_size, test_size])\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        angle_loader = torch.utils.data.DataLoader(self.angle_data_test, batch_size=self.batch_size*10)\n",
    "        level_loader = torch.utils.data.DataLoader(self.level_data_test, batch_size=self.batch_size*10)\n",
    "        return {'angle': angle_loader, 'level': level_loader}\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        angle_loader = torch.utils.data.DataLoader(self.angle_data_test, batch_size=self.batch_size*10)\n",
    "        level_loader = torch.utils.data.DataLoader(self.level_data_test, batch_size=self.batch_size*10)\n",
    "        return {'angle': angle_loader, 'level': level_loader}\n",
    "\n",
    "data_module = DataModule(data_dir='./dataset_level_angle/', batch_size=64)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db121f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(accelerator='gpu', max_epochs=1)\n",
    "trainer.test(model, data_module) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f5545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "imnet_mean = [0.485, 0.456, 0.406]\n",
    "imnet_std = [0.229, 0.224, 0.225]\n",
    "t = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=imnet_mean, std=imnet_std)\n",
    "        ])\n",
    "\n",
    "\n",
    "img = Image.open('./dataset_level_angle/level/eye/f51419ee4bcf2bd63b70dd26b779e5db6b46819d9997c41921faea0cfa131fb2.jpg')\n",
    "\n",
    "timg = t(img)\n",
    "plt.imshow(timg.numpy()[2, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4035fcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "timg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
